{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit ('.tgy_veribilimi')",
   "display_name": "Python 3.8.2 64-bit ('.tgy_veribilimi')",
   "metadata": {
    "interpreter": {
     "hash": "ba55969ab8b665a0d7ebc430170b2908b5d222710046023b08b5a17088334349"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ELASTICNET REGRESSION"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"verisetleri\\Hitters.csv\")\n",
    "df = df.dropna()\n",
    "dms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\n",
    "X = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_model = ElasticNet().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ -1.86256172,   8.70489065,   5.10426375,  -2.89875799,\n",
       "        -1.28642985,   5.24343682,   6.04480276,  -0.14701495,\n",
       "        -0.21566628,  -0.7897201 ,   1.80813117,   0.80914508,\n",
       "        -0.61262382,   0.26816203,   0.27172387,  -0.36530729,\n",
       "        19.2186222 , -31.16586592,   8.98369938])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "enet_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-6.465955602111876"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "enet_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([325.74706292, 776.06632333, 522.86508419, 107.64091955,\n",
       "       449.03139566, 997.76095723,  99.78828622, 311.33763086,\n",
       "       418.50335021, 879.9502608 ])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Tahmin\n",
    "enet_model.predict(X_train)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 577.79111731,  617.33202224, 1031.39113156,  364.95861575,\n",
       "        489.51894393,  300.74185842,  604.522666  ,  465.34678732,\n",
       "        901.44473965,  703.20357123])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "enet_model.predict(X_test)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = enet_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "357.1676548181244"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.41070222469326934"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "source": [
    "### Model Tunning "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_cv_model = ElasticNetCV(cv=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5230.7647364798695"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "enet_cv_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-38.5194055839429"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "enet_cv_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.62845434,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.09788752,  0.        ,\n",
       "        0.27265769,  0.19270075,  0.00758665,  0.3106529 ,  0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "enet_cv_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_tuned_model = ElasticNet(alpha=enet_cv_model.alpha_).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hata hesaplama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahmin etme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = enet_tuned_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "394.15280563218795"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(10, -2, 100)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_cv_model_aciklama = ElasticNetCV(alphas=alphas, cv=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_tuned_model_aciklama = ElasticNet(alpha=enet_cv_model_aciklama.alpha_).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_aciklama = enet_tuned_model_aciklama.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "393.9753065850553"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred_aciklama))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1_ratio -> Bunun değeri 0(sıfır) olduğunda  l2 cezalandırılması, 1 olduğunda ise l1 cezalandırılması yapılır.\n",
    "# Dolayısıyla 0 ile 1 arasında değişim olduğunda aslında cezalandırma metotlarının göreceli etkileri ifade edilmiş olur.\n",
    "# Biz uygulamamız kapsamında ikisininde etkisinin aynı düzeyde olmasını istediğimizden dolayı buradaki l1_ratio oranı değerini 0.5 yani öntanımlı değeri olarak bırakmış olduk.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha ve l1_ratio parametrelerini beraber düşünecek olursak l1_ratio için aranacak bir liste verdiğimizde - biz bir liste vermedik. normalde tunning bölümünde alpha için liste verebileceğimizi söylemiştik ve vermiştik. tunning bölümünde l1_ratio içinde liste verilebilir. İkisinin birbirlerine karşı olan durumlarında optimum sonucun ne zaman geldiğini inceleyebilmek adına yapılabilir.- l1_ratio için bir liste verildiğinde her bir l1_ratio değeri için farklı alpha değerleri olacaktır. Ki bu durumda bu alfalar ceza terimleri etkilerini modele yansıtmış olacaktır. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mElasticNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0ml1_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprecompute\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mselection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cyclic'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Linear regression with combined L1 and L2 priors as regularizer.\n",
      "\n",
      "Minimizes the objective function::\n",
      "\n",
      "        1 / (2 * n_samples) * ||y - Xw||^2_2\n",
      "        + alpha * l1_ratio * ||w||_1\n",
      "        + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
      "\n",
      "If you are interested in controlling the L1 and L2 penalty\n",
      "separately, keep in mind that this is equivalent to::\n",
      "\n",
      "        a * L1 + b * L2\n",
      "\n",
      "where::\n",
      "\n",
      "        alpha = a + b and l1_ratio = a / (a + b)\n",
      "\n",
      "The parameter l1_ratio corresponds to alpha in the glmnet R package while\n",
      "alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio\n",
      "= 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable,\n",
      "unless you supply your own sequence of alpha.\n",
      "\n",
      "Read more in the :ref:`User Guide <elastic_net>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "alpha : float, default=1.0\n",
      "    Constant that multiplies the penalty terms. Defaults to 1.0.\n",
      "    See the notes for the exact mathematical meaning of this\n",
      "    parameter. ``alpha = 0`` is equivalent to an ordinary least square,\n",
      "    solved by the :class:`LinearRegression` object. For numerical\n",
      "    reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
      "    Given this, you should use the :class:`LinearRegression` object.\n",
      "\n",
      "l1_ratio : float, default=0.5\n",
      "    The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For\n",
      "    ``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it\n",
      "    is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a\n",
      "    combination of L1 and L2.\n",
      "\n",
      "fit_intercept : bool, default=True\n",
      "    Whether the intercept should be estimated or not. If ``False``, the\n",
      "    data is assumed to be already centered.\n",
      "\n",
      "normalize : bool, default=False\n",
      "    This parameter is ignored when ``fit_intercept`` is set to False.\n",
      "    If True, the regressors X will be normalized before regression by\n",
      "    subtracting the mean and dividing by the l2-norm.\n",
      "    If you wish to standardize, please use\n",
      "    :class:`sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
      "    on an estimator with ``normalize=False``.\n",
      "\n",
      "precompute : bool or array-like of shape (n_features, n_features),                 default=False\n",
      "    Whether to use a precomputed Gram matrix to speed up\n",
      "    calculations. The Gram matrix can also be passed as argument.\n",
      "    For sparse input this option is always ``True`` to preserve sparsity.\n",
      "\n",
      "max_iter : int, default=1000\n",
      "    The maximum number of iterations\n",
      "\n",
      "copy_X : bool, default=True\n",
      "    If ``True``, X will be copied; else, it may be overwritten.\n",
      "\n",
      "tol : float, default=1e-4\n",
      "    The tolerance for the optimization: if the updates are\n",
      "    smaller than ``tol``, the optimization code checks the\n",
      "    dual gap for optimality and continues until it is smaller\n",
      "    than ``tol``.\n",
      "\n",
      "warm_start : bool, default=False\n",
      "    When set to ``True``, reuse the solution of the previous call to fit as\n",
      "    initialization, otherwise, just erase the previous solution.\n",
      "    See :term:`the Glossary <warm_start>`.\n",
      "\n",
      "positive : bool, default=False\n",
      "    When set to ``True``, forces the coefficients to be positive.\n",
      "\n",
      "random_state : int, RandomState instance, default=None\n",
      "    The seed of the pseudo random number generator that selects a random\n",
      "    feature to update. Used when ``selection`` == 'random'.\n",
      "    Pass an int for reproducible output across multiple function calls.\n",
      "    See :term:`Glossary <random_state>`.\n",
      "\n",
      "selection : {'cyclic', 'random'}, default='cyclic'\n",
      "    If set to 'random', a random coefficient is updated every iteration\n",
      "    rather than looping over features sequentially by default. This\n",
      "    (setting to 'random') often leads to significantly faster convergence\n",
      "    especially when tol is higher than 1e-4.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "coef_ : ndarray of shape (n_features,) or (n_targets, n_features)\n",
      "    parameter vector (w in the cost function formula)\n",
      "\n",
      "sparse_coef_ : sparse matrix of shape (n_features, 1) or             (n_targets, n_features)\n",
      "    ``sparse_coef_`` is a readonly property derived from ``coef_``\n",
      "\n",
      "intercept_ : float or ndarray of shape (n_targets,)\n",
      "    independent term in decision function.\n",
      "\n",
      "n_iter_ : list of int\n",
      "    number of iterations run by the coordinate descent solver to reach\n",
      "    the specified tolerance.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.linear_model import ElasticNet\n",
      ">>> from sklearn.datasets import make_regression\n",
      "\n",
      ">>> X, y = make_regression(n_features=2, random_state=0)\n",
      ">>> regr = ElasticNet(random_state=0)\n",
      ">>> regr.fit(X, y)\n",
      "ElasticNet(random_state=0)\n",
      ">>> print(regr.coef_)\n",
      "[18.83816048 64.55968825]\n",
      ">>> print(regr.intercept_)\n",
      "1.451...\n",
      ">>> print(regr.predict([[0, 0]]))\n",
      "[1.451...]\n",
      "\n",
      "\n",
      "Notes\n",
      "-----\n",
      "To avoid unnecessary memory duplication the X argument of the fit method\n",
      "should be directly passed as a Fortran-contiguous numpy array.\n",
      "\n",
      "See also\n",
      "--------\n",
      "ElasticNetCV : Elastic net model with best model selection by\n",
      "    cross-validation.\n",
      "SGDRegressor: implements elastic net regression with incremental training.\n",
      "SGDClassifier: implements logistic regression with elastic net penalty\n",
      "    (``SGDClassifier(loss=\"log\", penalty=\"elasticnet\")``).\n",
      "\u001b[1;31mFile:\u001b[0m           d:\\btkakademi_turkcellgy\\.tgy_veribilimi\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     Lasso\n"
     ],
     "name": "stdout"
    }
   ],
   "source": [
    "?ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# son"
   ]
  }
 ]
}
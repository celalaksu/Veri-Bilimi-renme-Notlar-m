{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# BÜYÜK VERİDE MAKİNE ÖĞRENMESİ\n",
    "### Uçtan uca makine öğrenmesi örneği"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init(\"C:\\spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark bağlantısının yapılandırılması\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "        .appName(\"pyspark_giris\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "# Bağlantının oluşturulması\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<SparkContext master=local appName=pyspark_giris>"
      ],
      "text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://DESKTOP-0UN70NV:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark_giris</code></dd>\n            </dl>\n        </div>\n        "
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.read.csv(\"./verisetleri/churn.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---+----------------+----+--------------+---------------+-----+---------+-----+\n|_c0|           Names| Age|Total_Purchase|Account_Manager|Years|Num_Sites|Churn|\n+---+----------------+----+--------------+---------------+-----+---------+-----+\n|  0|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|\n|  1|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|\n|  2|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|\n|  3|   Phillip White|42.0|       8010.76|              0| 6.71|     10.0|    1|\n|  4|  Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|    1|\n+---+----------------+----+--------------+---------------+-----+---------+-----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Değişken isimleri hepsi küçük yada hepsi büyük olacak şekilde değiştirilebilir. Yada camel tarzı kullanılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.toDF(*[c.lower() for c in spark_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---+----------------+----+--------------+---------------+-----+---------+-----+\n|_c0|           names| age|total_purchase|account_manager|years|num_sites|churn|\n+---+----------------+----+--------------+---------------+-----+---------+-----+\n|  0|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|\n|  1|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|\n|  2|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|\n|  3|   Phillip White|42.0|       8010.76|              0| 6.71|     10.0|    1|\n|  4|  Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|    1|\n+---+----------------+----+--------------+---------------+-----+---------+-----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumnRenamed(\"_C0\", \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[index: int, names: string, age: double, total_purchase: double, account_manager: int, years: double, num_sites: double, churn: int]"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "source": [
    "spark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "source": [
    "spark_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "execution_count": 128
    }
   ],
   "source": [
    "len(spark_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['index',\n",
       " 'names',\n",
       " 'age',\n",
       " 'total_purchase',\n",
       " 'account_manager',\n",
       " 'years',\n",
       " 'num_sites',\n",
       " 'churn']"
      ]
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "spark_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------+------------------+-------------+-----------------+-----------------+------------------+-----------------+------------------+-------------------+\n|summary|             index|        names|              age|   total_purchase|   account_manager|            years|         num_sites|              churn|\n+-------+------------------+-------------+-----------------+-----------------+------------------+-----------------+------------------+-------------------+\n|  count|               900|          900|              900|              900|               900|              900|               900|                900|\n|   mean|             449.5|         null|41.81666666666667|10062.82403333334|0.4811111111111111| 5.27315555555555| 8.587777777777777|0.16666666666666666|\n| stddev|259.95191863111916|         null|6.127560416916251|2408.644531858096|0.4999208935073339|1.274449013194616|1.7648355920350969| 0.3728852122772358|\n|    min|                 0|   Aaron King|             22.0|            100.0|                 0|              1.0|               3.0|                  0|\n|    max|               899|Zachary Walsh|             65.0|         18026.01|                 1|             9.15|              14.0|                  1|\n+-------+------------------+-------------+-----------------+-----------------+------------------+-----------------+------------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     0                    1                   2      3  \\\n",
       "summary          count                 mean              stddev    min   \n",
       "age                900    41.81666666666667   6.127560416916251   22.0   \n",
       "total_purchase     900    10062.82403333334   2408.644531858096  100.0   \n",
       "account_manager    900   0.4811111111111111  0.4999208935073339      0   \n",
       "years              900     5.27315555555555   1.274449013194616    1.0   \n",
       "num_sites          900    8.587777777777777  1.7648355920350969    3.0   \n",
       "churn              900  0.16666666666666666  0.3728852122772358      0   \n",
       "\n",
       "                        4  \n",
       "summary               max  \n",
       "age                  65.0  \n",
       "total_purchase   18026.01  \n",
       "account_manager         1  \n",
       "years                9.15  \n",
       "num_sites            14.0  \n",
       "churn                   1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>summary</th>\n      <td>count</td>\n      <td>mean</td>\n      <td>stddev</td>\n      <td>min</td>\n      <td>max</td>\n    </tr>\n    <tr>\n      <th>age</th>\n      <td>900</td>\n      <td>41.81666666666667</td>\n      <td>6.127560416916251</td>\n      <td>22.0</td>\n      <td>65.0</td>\n    </tr>\n    <tr>\n      <th>total_purchase</th>\n      <td>900</td>\n      <td>10062.82403333334</td>\n      <td>2408.644531858096</td>\n      <td>100.0</td>\n      <td>18026.01</td>\n    </tr>\n    <tr>\n      <th>account_manager</th>\n      <td>900</td>\n      <td>0.4811111111111111</td>\n      <td>0.4999208935073339</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>years</th>\n      <td>900</td>\n      <td>5.27315555555555</td>\n      <td>1.274449013194616</td>\n      <td>1.0</td>\n      <td>9.15</td>\n    </tr>\n    <tr>\n      <th>num_sites</th>\n      <td>900</td>\n      <td>8.587777777777777</td>\n      <td>1.7648355920350969</td>\n      <td>3.0</td>\n      <td>14.0</td>\n    </tr>\n    <tr>\n      <th>churn</th>\n      <td>900</td>\n      <td>0.16666666666666666</td>\n      <td>0.3728852122772358</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 130
    }
   ],
   "source": [
    "spark_df.select(\"age\", \"total_purchase\", \"account_manager\", \"years\", \"num_sites\", \"churn\").describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sınıflandırma problemi. Müşteriler bizi terk edecek mi etmeyecek mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERİ ÖNİŞLEME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varolan değişken üzerinden değişken türetip yeni değişken ekleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumn(\"age_kare\", spark_df.age**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+----------------+----+--------------+---------------+-----+---------+-----+--------+\n|index|           names| age|total_purchase|account_manager|years|num_sites|churn|age_kare|\n+-----+----------------+----+--------------+---------------+-----+---------+-----+--------+\n|    0|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|  1764.0|\n|    1|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|  1681.0|\n|    2|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|  1444.0|\n+-----+----------------+----+--------------+---------------+-----+---------+-----+--------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Büyük veri dünyasında özellikle makine öğrenmesi tarafında algoritmaları kullanırken bağımlı değişkeni ve bağımsız değişkenleri özel bir şekilde ifade etmek gerekmektedir.\n",
    "# Burada bağımlı değişkenimizi sanki integer mış gibi düşünüp - ki siz bunu başka problemlere uyguladığınızda elinizde string formunda olan bağımlı değişkenler de olabilecektir. Sanki string miş gibi düşünüp bir string bağımlı değişkeni oluşturma işlemi gerçekleştirmiş olacağız. "
   ]
  },
  {
   "source": [
    "## Bağımli değişkeni belirtme, dönüştürme yani ayarlanması"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bağımlı değişken belirlenmekte ve \"label\" olarak etiketlenmektedir.\n",
    "stringIndexer = StringIndexer(inputCol = \"churn\", outputCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yukarıdaki değişikliği spark_df e uygulanıyor.\n",
    "mod = stringIndexer.fit(spark_df)\n",
    "\n",
    "# İndexlerin integer a göre dönüştürülmesi\n",
    "indexed = mod.transform(spark_df)\n",
    "spark_df = indexed.withColumn(\"label\", indexed[\"label\"].cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+----------------+----+--------------+---------------+-----+---------+-----+--------+-----+\n|index|           names| age|total_purchase|account_manager|years|num_sites|churn|age_kare|label|\n+-----+----------------+----+--------------+---------------+-----+---------+-----+--------+-----+\n|    0|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|  1764.0|    1|\n|    1|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|  1681.0|    1|\n|    2|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|  1444.0|    1|\n|    3|   Phillip White|42.0|       8010.76|              0| 6.71|     10.0|    1|  1764.0|    1|\n|    4|  Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|    1|  1369.0|    1|\n+-----+----------------+----+--------------+---------------+-----+---------+-----+--------+-----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(5)"
   ]
  },
  {
   "source": [
    "## Bağımsız değişkenlerin ayarlanması"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['index',\n",
       " 'names',\n",
       " 'age',\n",
       " 'total_purchase',\n",
       " 'account_manager',\n",
       " 'years',\n",
       " 'num_sites',\n",
       " 'churn',\n",
       " 'age_kare',\n",
       " 'label']"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "spark_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagimsiz_degiskenler = [\"age\", \"total_purchase\", \"account_manager\", \"years\", \"num_sites\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tüm değişkenleri sanki tek bir vektördeymişçesine dönüştürme işlemine tabi tutmamız gerekiyor. Yani bir gözlemin değişken değerleri tek boyutlu bir matrise dönüştürülüyor.\n",
    "vectorAssembler = VectorAssembler(inputCols = bagimsiz_degiskenler, outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_df = vectorAssembler.transform(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+----------------+----+--------------+---------------+-----+---------+-----+--------+-----+--------------------+\n|index|           names| age|total_purchase|account_manager|years|num_sites|churn|age_kare|label|            features|\n+-----+----------------+----+--------------+---------------+-----+---------+-----+--------+-----+--------------------+\n|    0|Cameron Williams|42.0|       11066.8|              0| 7.22|      8.0|    1|  1764.0|    1|[42.0,11066.8,0.0...|\n|    1|   Kevin Mueller|41.0|      11916.22|              0|  6.5|     11.0|    1|  1681.0|    1|[41.0,11916.22,0....|\n|    2|     Eric Lozano|38.0|      12884.75|              0| 6.67|     12.0|    1|  1444.0|    1|[38.0,12884.75,0....|\n|    3|   Phillip White|42.0|       8010.76|              0| 6.71|     10.0|    1|  1764.0|    1|[42.0,8010.76,0.0...|\n|    4|  Cynthia Norton|37.0|       9191.58|              0| 5.56|      9.0|    1|  1369.0|    1|[37.0,9191.58,0.0...|\n+-----+----------------+----+--------------+---------------+-----+---------+-----+--------+-----+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "va_df.show(5)"
   ]
  },
  {
   "source": [
    "### SONUÇ VERİ SETİNİN OLUŞTURULMASI LABEL VE FEATURES IN ÇIKARILMASI"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = va_df.select([\"features\",\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+-----+\n|            features|label|\n+--------------------+-----+\n|[42.0,11066.8,0.0...|    1|\n|[41.0,11916.22,0....|    1|\n|[38.0,12884.75,0....|    1|\n|[42.0,8010.76,0.0...|    1|\n|[37.0,9191.58,0.0...|    1|\n+--------------------+-----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "final_df.show(5)"
   ]
  },
  {
   "source": [
    "### TEST - TRAIN AYRIMININ YAPILMASI"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = final_df.randomSplit([0.70, 0.30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: int]"
      ]
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: int]"
      ]
     },
     "metadata": {},
     "execution_count": 147
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BÖYLECE VERİ MODELLEMEYE HAZIR HALE GETİRİLDİ."
   ]
  },
  {
   "source": [
    "## GBM ( Gradient Boosting Machine ) ile Müşteri Terk Modellemesi"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GBTClassifier(maxIter = 10, featuresCol = \"features\", labelCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_model = gbm.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<SparkContext master=local appName=pyspark_giris>"
      ],
      "text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://DESKTOP-0UN70NV:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark_giris</code></dd>\n            </dl>\n        </div>\n        "
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arayüze bakıldığında arka planda RandomForest ve DecisionTree gibi yapıların açıştırıldığını görebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAHMİN ETME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm_model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# İlkel test hatasının hesaplanması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: int, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred içerisinden label lar ve tahmin edilen değerlerin seçilmesi\n",
    "ac = y_pred.select(\"label\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8514492753623188"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "# Gerçek değerler ile (ac.label), tahmin edilen değerleri karşılaştıracak (ac.prediction), True dönen değerleri yani doğru tahmin edilen değerlerin sayısını toplam sayıya bölecek. Böylece accuracy değeri hesaplanacak\n",
    "ac.filter(ac.label == ac.prediction).count() / ac.count()"
   ]
  },
  {
   "source": [
    " ## MODEL TUNNING"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL OPTİMİZAZYONU İÇİN GİRMEMİZ GEREKEN, MODEL NESNESİ VE PARAMETRE VB. AYARLAR\n",
    "\n",
    "# Binary classification değerlendirmesine yönelik fonksiyon\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# PaamGridBuilder : Parametre gridleri için fonksiyon\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Başarı değerlendirmesi için sınıflandırma nesnesi. İkili sınıflandırma (yani 0,1; yani evet, hayır) yaptığımız için bunu kullanıyoruz.\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    ".addGrid(gbm.maxDepth, [2, 4,6])\n",
    ".addGrid(gbm.maxBins, [20, 30])\n",
    ".addGrid(gbm.maxIter, [10, 20])\n",
    ".build())\n",
    "\n",
    "# estimator--> tahminci gbm nesnesi\n",
    "# evaluator--> başarıyı ölçmek için kullanıcak yol-nesne-fonksiyon\n",
    "# numFolds --> Kaç katlı cross validation yapılacak\n",
    "cv = CrossValidator(estimator = gbm, estimatorParamMaps = paramGrid, evaluator = evaluator, numFolds = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FİT ETME : İşlem devam ederken arayüzden çalışan işlemleri takip edebilirsiniz.\n",
    "cvModel = cv.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAHMİN ETME VE HATA BULMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cvModel.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = y_pred.select(\"label\", \"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8804347826086957"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "ac.filter(ac.label == ac.prediction).count()/ac.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yaklaşık olarak % 90 başarı ile tahmainler yapılabilmektedir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeni Müşteri Terk Eder mi? Etmez Mİ?"
   ]
  },
  {
   "source": [
    "## MODELİN KULLANILMASI : YENİ VERİ ÜZERİNDE TEST EDİLMESİ"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['names', 'age', 'total_purchase', 'account_manager', 'years',\n",
       "       'num_sites'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "names = pd.Series([\"Celal AKSU\", \"Taner Gün\", \"Eylem\", \"Berkay\", \"Özge\"])\n",
    "age = pd.Series([38, 43, 34, 50, 40])\n",
    "total_purchase = pd.Series([30000, 10000, 6000, 30000, 100000])\n",
    "account_manager = pd.Series([1, 0, 0, 1, 1])\n",
    "years = pd.Series([20, 10, 3, 8, 30])\n",
    "num_sites = pd.Series([30, 8, 8, 6, 50,])\n",
    "\n",
    "yeni_musteriler = pd.DataFrame({'names':names,\n",
    "'age':age,\n",
    "'total_purchase':total_purchase,\n",
    "'account_manager':account_manager,\n",
    "'years':years,\n",
    "'num_sites':num_sites})\n",
    "\n",
    "yeni_musteriler.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu verileri büyük veri ortamının anlayacağı forma sokmamız ve büyük veri ortamına göndermemiz gerekir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biz burada kendi localimizde el yordamıyla bir pandas dataframe oluşturduk. Bunu kurmuş olduğumuz spark makine öğrenmesi model nesnesiyle tahmin edebilmek adına bunu spark ın analayabileceği bir dile çevirmemiz gerekiyor. Yani SPARK DATAFRAME ini çevirmemiz gerekiyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeni_sdf = spark.createDataFrame(yeni_musteriler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+---+--------------+---------------+-----+---------+\n|     names|age|total_purchase|account_manager|years|num_sites|\n+----------+---+--------------+---------------+-----+---------+\n|Celal AKSU| 38|         30000|              1|   20|       30|\n| Taner Gün| 43|         10000|              0|   10|        8|\n|     Eylem| 34|          6000|              0|    3|        8|\n|    Berkay| 50|         30000|              1|    8|        6|\n|      Özge| 40|        100000|              1|   30|       50|\n+----------+---+--------------+---------------+-----+---------+\n\n"
     ]
    }
   ],
   "source": [
    "yeni_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark dataframe e çevirme işlemi başarılı olduğu gözlenmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu verileri ayrıca model nesnesinin anlayacağı formata çevirmemiz gerekiyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yani bağımsız değikenleri tek bir vektöre çevirmemiz gerekir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeni_musteriler = vectorAssembler.transform(yeni_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+---+--------------+---------------+-----+---------+--------------------+\n|     names|age|total_purchase|account_manager|years|num_sites|            features|\n+----------+---+--------------+---------------+-----+---------+--------------------+\n|Celal AKSU| 38|         30000|              1|   20|       30|[38.0,30000.0,1.0...|\n| Taner Gün| 43|         10000|              0|   10|        8|[43.0,10000.0,0.0...|\n|     Eylem| 34|          6000|              0|    3|        8|[34.0,6000.0,0.0,...|\n|    Berkay| 50|         30000|              1|    8|        6|[50.0,30000.0,1.0...|\n|      Özge| 40|        100000|              1|   30|       50|[40.0,100000.0,1....|\n+----------+---+--------------+---------------+-----+---------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "yeni_musteriler.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cvModel.transform(yeni_musteriler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+----------+\n|     names|prediction|\n+----------+----------+\n|Celal AKSU|       1.0|\n| Taner Gün|       0.0|\n|     Eylem|       0.0|\n|    Berkay|       0.0|\n|      Özge|       1.0|\n+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "results.select(\"names\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 terkedecek, 0 terketmeyecek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<SparkContext master=local appName=pyspark_giris>"
      ],
      "text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://DESKTOP-0UN70NV:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark_giris</code></dd>\n            </dl>\n        </div>\n        "
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}